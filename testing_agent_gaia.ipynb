{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "from tools.reformulator import prepare_response\n",
    "from tools.run_agents import get_single_file_description, get_zip_description\n",
    "from tools.text_inspector_tool import TextInspectorTool\n",
    "from tools.text_web_browser import (\n",
    "    ArchiveSearchTool,\n",
    "    FinderTool,\n",
    "    FindNextTool,\n",
    "    PageDownTool,\n",
    "    PageUpTool,\n",
    "    SimpleTextBrowser,\n",
    "    VisitTool,\n",
    ")\n",
    "from tools.visual_qa import VisualQATool\n",
    "from tools.agent_with_tools import create_plan_and_execute_agent, PlanExecute\n",
    "\n",
    "from smolagents import (\n",
    "    CodeAgent,\n",
    "    GoogleSearchTool,  # make sure this is distinct from Serp/BSerp tools\n",
    "    LiteLLMModel,\n",
    "    Model,\n",
    "    ToolCallingAgent,\n",
    ")\n",
    "\n",
    "from langchain.chat_models import init_chat_model, ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper, SerpAPIWrapper\n",
    "from langchain_community.tools import BraveSearch\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchResults\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Setup\n",
    "load_dotenv()\n",
    "login(os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "append_answer_lock = threading.Lock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing AI Agent on sample questions\n",
    "\n",
    "question = \"when is aymar de bergeyck born?\"\n",
    "\n",
    "config = {\"recursion_limit\": 50}\n",
    "graph = create_plan_and_execute_agent(\n",
    "    llm_name_planner=\"gpt-4.1-mini\",\n",
    "    llm_name_executor=\"gpt-4.1-mini\",\n",
    "    llm_name_replanner=\"gpt-4.1-mini\",\n",
    "    llm_name_answer=\"gpt-4.1-mini\")\n",
    "\n",
    "initial_state = PlanExecute(\n",
    "    question=question,\n",
    "    plan=[],\n",
    "    intermediate_responses=[],\n",
    "    response=\"\",\n",
    "    current_step=0,\n",
    "    error_count=0,\n",
    "    validation=None,\n",
    "    agent_finished=False\n",
    ")\n",
    "\n",
    "workflow = initial_state\n",
    "workflow =  graph.invoke(initial_state, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Response:\", workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_gaia_dataset(use_raw_dataset: bool, set_to_run: str) -> datasets.Dataset:\n",
    "    if not os.path.exists(\"data/gaia\"):\n",
    "        print('gaia dataset path doesnt exist')\n",
    "        if use_raw_dataset:\n",
    "            print('in use raw dataset')\n",
    "            snapshot_download(\n",
    "                repo_id=\"gaia-benchmark/GAIA\",\n",
    "                repo_type=\"dataset\",\n",
    "                local_dir=\"data/gaia\",\n",
    "                ignore_patterns=[\".gitattributes\", \"README.md\"],\n",
    "            )\n",
    "        else:\n",
    "            # WARNING: this dataset is gated: make sure you visit the repo to require access.\n",
    "            snapshot_download(\n",
    "                repo_id=\"smolagents/GAIA-annotated\",\n",
    "                repo_type=\"dataset\",\n",
    "                local_dir=\"data/gaia\",\n",
    "                ignore_patterns=[\".gitattributes\", \"README.md\"],\n",
    "            )\n",
    "\n",
    "    def preprocess_file_paths(row):\n",
    "        if len(row[\"file_name\"]) > 0:\n",
    "            row[\"file_name\"] = f\"data/gaia/{set_to_run}/\" + row[\"file_name\"]\n",
    "        return row\n",
    "    \n",
    "    eval_ds = datasets.load_dataset(\n",
    "        \"data/gaia/GAIA.py\",\n",
    "        name=\"2023_all\",\n",
    "        split=set_to_run,\n",
    "    )\n",
    "\n",
    "    eval_ds = eval_ds.rename_columns({\"Question\": \"question\", \"Final answer\": \"true_answer\", \"Level\": \"task\"})\n",
    "    eval_ds = eval_ds.map(preprocess_file_paths)\n",
    "    return eval_ds\n",
    "\n",
    "def append_answer(entry: dict, jsonl_file: str) -> None:\n",
    "    jsonl_path = Path(jsonl_file)\n",
    "    jsonl_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with append_answer_lock, open(jsonl_file, \"a\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(json.dumps(entry) + \"\\n\")\n",
    "    assert jsonl_path.exists(), \"File not found!\"\n",
    "    print(\"Answer exported to file:\", jsonl_path.resolve())\n",
    "\n",
    "def answer_single_question(\n",
    "    example: dict, answers_file: str\n",
    ") -> None:\n",
    "    print('EXAMPLE', example)\n",
    "    question = example[\"question\"]\n",
    "\n",
    "    document_inspection_tool = TextInspectorTool(\n",
    "            model=init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", temperature=0), \n",
    "            text_limit=10000)\n",
    "    visual_inspection_tool = VisualQATool(model=init_chat_model(\"gpt-4.1-mini\", model_provider=\"openai\", temperature=0))\n",
    "\n",
    "    if example[\"file_name\"]:\n",
    "        if \".zip\" in example[\"file_name\"]:\n",
    "            prompt_use_files = \"\\n\\nTo solve the task above, you will have to use these attached files:\\n\"\n",
    "            prompt_use_files += get_zip_description(\n",
    "                example[\"file_name\"], None, visual_inspection_tool, document_inspection_tool\n",
    "            )\n",
    "        else:\n",
    "            prompt_use_files = \"\\n\\nTo solve the task above, you will have to use this attached file:\\n\"\n",
    "            prompt_use_files += get_single_file_description(\n",
    "                example[\"file_name\"], None, visual_inspection_tool, document_inspection_tool\n",
    "            )\n",
    "\n",
    "        question += prompt_use_files\n",
    "    \n",
    "    # CREATE AGENT\n",
    "    config = {\"recursion_limit\": 50}\n",
    "    graph = create_plan_and_execute_agent(\n",
    "        llm_name_planner=\"gpt-4.1\",\n",
    "        llm_name_executor=\"gpt-4.1\",\n",
    "        llm_name_replanner=\"gpt-4.1\",\n",
    "        llm_name_answer=\"gpt-4.1\",\n",
    "        llm_text_inspector = \"gpt-4.1\",\n",
    "        llm_visual_qa = \"gpt-4.1\"\n",
    "        )\n",
    "\n",
    "    initial_state = PlanExecute(\n",
    "        question=question,\n",
    "        plan=[],\n",
    "        intermediate_responses=[],\n",
    "        response=\"\",\n",
    "        current_step=0,\n",
    "        error_count=0,\n",
    "        validation=None,\n",
    "        agent_finished=False\n",
    "    )\n",
    "\n",
    "    start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    try: \n",
    "        # Run Agent\n",
    "        # print('Question:', question)\n",
    "        workflow = initial_state\n",
    "        workflow =  graph.invoke(initial_state, config=config)\n",
    "\n",
    "        # print('QUESTION')\n",
    "        # print(workflow[\"question\"])\n",
    "        # print(\"STEPS\")\n",
    "        # previous_steps_with_answers = \"\\n\".join(\n",
    "        #     f\"{i}. INSTRUCTION: {workflow['plan'][i]} ANSWER: {workflow['intermediate_responses'][i]}\\n\" for i in range(len(workflow['intermediate_responses']))\n",
    "        # )\n",
    "        # print(previous_steps_with_answers)\n",
    "        # print(\"Current step: \", workflow[\"current_step\"])\n",
    "        # print(\"RESPONSE\")\n",
    "        # print(workflow[\"response\"])\n",
    "        # print('TRUE RESPONSE')\n",
    "        # print(example['true_answer'])\n",
    "        # response = \"No response was found\"\n",
    "        # for event in graph.stream(initial_state, config=config):\n",
    "        #     if \"planner\" in event:\n",
    "        #         print('PLAN')\n",
    "        #         for i, p in enumerate(event['planner']['plan']):\n",
    "        #             print(f\"Step {i}: {p}\")\n",
    "        #     elif \"agent\" in event:\n",
    "        #         print('AGENT')\n",
    "        #         print(event['agent']['intermediate_responses'])\n",
    "        #     elif \"replan\" in event:\n",
    "        #         if 'plan' in event['replan']:\n",
    "        #             print('REPLAN')\n",
    "        #             for i, p in enumerate(event['replan']['plan']):\n",
    "        #                 print(f\"Step {i}: {p}\")\n",
    "        #         else:\n",
    "        #             print('REPLAN ERROR')\n",
    "        #             print(event['replan'])\n",
    "        #     elif 'answer' in event:\n",
    "        #         response = event['answer']['response']\n",
    "        #         print('RESPONSE')\n",
    "        #         print(response)\n",
    "        #         break\n",
    "        # workflow = {}\n",
    "\n",
    "        raised_exception = False\n",
    "\n",
    "    except Exception as e: \n",
    "        print(\"Error on\", question, e)\n",
    "        exception = e\n",
    "        raised_exception = True\n",
    "\n",
    "    end_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    annotated_example = {\n",
    "        \"question\": example[\"question\"],\n",
    "        \"augmented_question\": question,\n",
    "        \"response\": workflow[\"response\"].replace('FINAL ANSWER: ', ''),\n",
    "        \"plan\": workflow[\"plan\"],\n",
    "        \"intermediate_responses\": workflow[\"intermediate_responses\"],\n",
    "        \"current_step\": workflow[\"current_step\"],\n",
    "        \"plan_with_answers\": \"\\n\".join(\n",
    "            f\"{i}. INSTRUCTION: {workflow['plan'][i]} ANSWER: {workflow['intermediate_responses'][i]}\\n\" for i in range(len(workflow['intermediate_responses']))\n",
    "        ),\n",
    "        \"agent_error\": str(exception) if raised_exception else None,\n",
    "        \"task\": example[\"task\"],\n",
    "        \"task_id\": example[\"task_id\"],\n",
    "        \"true_answer\": example[\"true_answer\"],\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time,\n",
    "    }\n",
    "    print('-------------------------------------------------------------')\n",
    "    list_print = ['question', 'augmented_question', 'plan_with_answers', 'response', 'true_answer']\n",
    "    for k in list_print:\n",
    "        print(k)\n",
    "        print(annotated_example[k])\n",
    "    print('-------------------------------------------------------------')\n",
    "\n",
    "    append_answer(annotated_example, answers_file)\n",
    "\n",
    "\n",
    "def get_examples_to_answer(answers_file: str, eval_ds: datasets.Dataset) -> list[dict]:\n",
    "    print(f\"Loading answers from {answers_file}...\")\n",
    "    try:\n",
    "        done_questions = pd.read_json(answers_file, lines=True)[\"question\"].tolist()\n",
    "        print(f\"Found {len(done_questions)} previous results!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error when loading records: \", e)\n",
    "        print(\"No usable records! ▶️ Starting new.\")\n",
    "        done_questions = []\n",
    "    return [line for line in eval_ds.to_list() if line[\"question\"] not in done_questions and line[\"file_name\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"test3\"\n",
    "set_to_run = \"validation\"\n",
    "use_raw_dataset = True\n",
    "levels_to_run = [1]\n",
    "eval_ds = load_gaia_dataset(use_raw_dataset, set_to_run)\n",
    "\n",
    "print(\"Loaded evaluation dataset:\")\n",
    "print(pd.DataFrame(eval_ds)[\"task\"].value_counts())\n",
    "\n",
    "answers_file = f\"output/{set_to_run}/{run_name}.jsonl\"\n",
    "tasks_to_run = get_examples_to_answer(answers_file, eval_ds)\n",
    "\n",
    "for example in tqdm(tasks_to_run, desc=\"Processing tasks\"):\n",
    "    if int(example[\"task\"]) in levels_to_run:\n",
    "        answer_single_question(example, answers_file)\n",
    "\n",
    "print(\"All tasks processed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
